{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 64 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ast\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datamol as dm\n",
    "from molfeat.calc.atom import AtomCalculator, AtomMaterialCalculator\n",
    "from molfeat.calc.bond import EdgeMatCalculator, BondCalculator\n",
    "from molfeat.trans.graph import PYGGraphTransformer\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.warning')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def convert_string_to_list(string):\n",
    "    try:\n",
    "        return ast.literal_eval(string)\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/QM_137k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CDD'] = data['CDD'].apply(convert_string_to_list)\n",
    "columns_to_drop = ['hirshfeld_charges', 'hirshfeld_fukui_elec', 'hirshfeld_fukui_neu', 'NMR_SC', 'bond_length_matrix', 'bond_index_matrix']\n",
    "data = data.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd304ebe5b864d28861bcb7f4fc2cc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/136219 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smiles_column = \"smiles\"\n",
    "\n",
    "def _preprocess(i, row):\n",
    "\n",
    "    dm.disable_rdkit_log()\n",
    "\n",
    "    mol = dm.to_mol(row[smiles_column], ordered=True, add_hs=True, kekulize=True)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    mol = dm.fix_mol(mol)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    mol = dm.sanitize_mol(mol, sanifix=True, charge_neutral=True, add_hs=True)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    mol = dm.standardize_mol(\n",
    "        mol, disconnect_metals=False, normalize=True, reionize=True, uncharge=False, stereo=True\n",
    "    )\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    row[\"smiles\"] = dm.standardize_smiles(dm.to_smiles(mol))\n",
    "\n",
    "    row['mol'] = mol\n",
    "    return row\n",
    "\n",
    "\n",
    "processed_results = dm.parallelized(_preprocess, data.iterrows(), arg_type=\"args\", n_jobs=-1, progress=True, total=len(data))\n",
    "processed_results = [result for result in processed_results if result is not None]\n",
    "data = pd.DataFrame(processed_results)\n",
    "\n",
    "mols = data[\"mol\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 4/130 [00:03<01:17,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "def process_batch(mols, data, start_idx, end_idx, pyg_trans, skipatom_model):\n",
    "    results = []\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        mol = mols[idx]\n",
    "        try:\n",
    "            graph = pyg_trans.transform([mol])[0]\n",
    "            \n",
    "            # Process targets\n",
    "            graph.y = torch.tensor([data['CDD'].iloc[idx]], dtype=torch.float32).squeeze()\n",
    "            graph.smiles = data['smiles'].iloc[idx]\n",
    "            \n",
    "            if skipatom_model:\n",
    "                atom_symbols = [atom.GetSymbol() for atom in mol.GetAtoms()]\n",
    "                atom_features = [skipatom_model.vectors[skipatom_model.dictionary[symbol]] for symbol in atom_symbols]\n",
    "                atom_features_tensor = torch.tensor(np.array(atom_features, dtype=np.float32))\n",
    "                graph.x = torch.cat([graph.x, atom_features_tensor], dim=1)\n",
    "            \n",
    "            results.append(graph)\n",
    "        except Exception as e:\n",
    "            print(f\"Err {e}\")\n",
    "    return results\n",
    "\n",
    "def process_dataset(mols, data, n_jobs=-1, skipatom_model=None, progress_bar=True, batch_size=1000):\n",
    "    pyg_trans = PYGGraphTransformer(\n",
    "        atom_featurizer=AtomCalculator(),\n",
    "        bond_featurizer=BondCalculator(),\n",
    "        explicit_hydrogens=True,\n",
    "        self_loop=False,\n",
    "        canonical_atom_order=True,\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "\n",
    "    total = len(mols)\n",
    "    tasks = (total + batch_size - 1) // batch_size\n",
    "\n",
    "    if progress_bar:\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(process_batch)(mols, data, i * batch_size, min((i + 1) * batch_size, total), pyg_trans, skipatom_model) for i in tqdm(range(tasks)))\n",
    "    else:\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(process_batch)(mols, data, i * batch_size, min((i + 1) * batch_size, total), pyg_trans, skipatom_model) for i in range(tasks))\n",
    "    \n",
    "    dataset = [item for sublist in results for item in sublist]\n",
    "    return dataset\n",
    "\n",
    "dataset = process_dataset(mols, data, n_jobs=4, skipatom_model=None, progress_bar=True, batch_size=1000)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    inconsistencies = []\n",
    "    inconsistency_counts = {'size_mismatch': 0}\n",
    "    indices_to_remove = []\n",
    "\n",
    "    for idx, data_point in enumerate(dataset):\n",
    "        if data_point.x.shape[0] != data_point.y.shape[0]:\n",
    "            inconsistencies.append((idx, data_point.x.shape[0], data_point.y.shape[0], data_point.smiles))\n",
    "            inconsistency_counts['size_mismatch'] += 1\n",
    "            indices_to_remove.append(idx)\n",
    "\n",
    "    dataset_clean = [data_point for idx, data_point in enumerate(dataset) if idx not in indices_to_remove]\n",
    "\n",
    "    if inconsistencies:\n",
    "        print(\"Inconsistencies found in the following dataset elements:\")\n",
    "        for incon in inconsistencies:\n",
    "            print(f\"Index: {incon[0]}, X size: {incon[1]}, Y size: {incon[2]}, SMILES: {incon[3]}\")\n",
    "    else:\n",
    "        print(\"All dataset elements are consistent.\")\n",
    "\n",
    "    print(\"Number of different types of inconsistencies:\")\n",
    "    for key, value in inconsistency_counts.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    print(f\"Removed {len(dataset) - len(dataset_clean)} inconsistent elements. New dataset size: {len(dataset_clean)}\")\n",
    "    return dataset_clean\n",
    "\n",
    "dataset_clean = clean_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset_clean, f'../../data/QM_137k_atom.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
