{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import optuna\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturizationParameters:\n",
    "    def __init__(self):\n",
    "        self.max_atomic_num = 100\n",
    "        self.atom_features = {\n",
    "            'atomic_num': list(range(self.max_atomic_num)),\n",
    "            'degree': [0, 1, 2, 3, 4, 5],\n",
    "            'formal_charge': [-1, -2, 1, 2, 0],\n",
    "            'chiral_tag': [0, 1, 2, 3],\n",
    "            'num_Hs': [0, 1, 2, 3, 4],\n",
    "            'hybridization': [\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "                Chem.rdchem.HybridizationType.SP3D,\n",
    "                Chem.rdchem.HybridizationType.SP3D2\n",
    "            ],\n",
    "        }\n",
    "        self.atom_fdim = sum(len(choices) + 1 for choices in self.atom_features.values()) + 2\n",
    "\n",
    "def onek_encoding_unk(value, choices):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "def atom_features(atom, params):\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, params.atom_features['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), params.atom_features['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), params.atom_features['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), params.atom_features['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), params.atom_features['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), params.atom_features['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "    return features\n",
    "\n",
    "PARAMS = {\n",
    "    'BOND_FDIM': 10\n",
    "}\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond) -> List[Union[bool, int, float]]:\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (PARAMS['BOND_FDIM'] - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            bond.GetIsConjugated() if bt is not None else 0,\n",
    "            bond.IsInRing() if bt is not None else 0\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond\n",
    "\n",
    "\n",
    "class MoleculeData:\n",
    "    def __init__(self, smiles, target, addHs=True):\n",
    "        self.smiles = smiles\n",
    "        self.target = torch.tensor(target, dtype=torch.float)\n",
    "        self.mol = Chem.MolFromSmiles(smiles)\n",
    "        if addHs:\n",
    "            self.mol = Chem.AddHs(self.mol)\n",
    "        self.params = FeaturizationParameters()\n",
    "        self.edge_index, self.edge_attr = self.construct_graph()\n",
    "\n",
    "    def construct_graph(self):\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for bond in self.mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[start, end], [end, start]])\n",
    "            edge_attr.extend([bond_features(bond), bond_features(bond)])  # Добавляем признаки для обеих направлений связи\n",
    "        return torch.tensor(edge_index).t().contiguous(), torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    def generate_atom_features(self):\n",
    "        features = []\n",
    "        for atom in self.mol.GetAtoms():\n",
    "            features.append(atom_features(atom, self.params))\n",
    "        return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataframe, smiles_column='smiles', target_column='target', addHs=True, n_jobs=-1):\n",
    "        super(MoleculeDataset, self).__init__()\n",
    "        self.data_list = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(lambda row: MoleculeData(row[smiles_column], row[target_column], addHs))(\n",
    "                row) for _, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0]))\n",
    "\n",
    "    def len(self): \n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        molecule_data = self.data_list[idx]\n",
    "        x = molecule_data.generate_atom_features()\n",
    "        edge_index = molecule_data.edge_index\n",
    "        edge_attr = molecule_data.edge_attr\n",
    "        y = molecule_data.target\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        data.smiles = molecule_data.smiles\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoleculeDataset(136219)\n",
      "Data(x=[31, 133], edge_index=[2, 64], edge_attr=[64, 14], y=[31], smiles='CNC(=S)N/N=C/c1c(O)ccc2ccccc12')\n",
      "Data(x=[36, 133], edge_index=[2, 76], edge_attr=[76, 14], y=[36], smiles='O=C(NCCn1cccc1)c1cccc2ccccc12')\n"
     ]
    }
   ],
   "source": [
    "molecule_dataset = torch.load('../data/QM_137k.pt')\n",
    "print(molecule_dataset)\n",
    "for i in range(2):\n",
    "    print(molecule_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Train Dataset:   1%|          | 713/95353 [00:00<01:33, 1015.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Train Dataset: 100%|██████████| 95353/95353 [01:35<00:00, 998.69it/s] \n",
      "Creating Validation Dataset: 100%|██████████| 13622/13622 [00:12<00:00, 1063.31it/s]\n",
      "Creating Test Dataset: 100%|██████████| 27244/27244 [00:25<00:00, 1055.73it/s]\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(molecule_dataset)))\n",
    "train_val_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.125, random_state=42)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "train_dataset = [molecule_dataset[i] for i in tqdm(train_indices, desc=\"Creating Train Dataset\")]\n",
    "val_dataset = [molecule_dataset[i] for i in tqdm(val_indices, desc=\"Creating Validation Dataset\")]\n",
    "test_dataset = [molecule_dataset[i] for i in tqdm(test_indices, desc=\"Creating Test Dataset\")]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataset = DataLoader(molecule_dataset, batch_size=batch_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model:\n",
      "GATv2Model(\n",
      "  (conv1): GATv2Conv(133, 64, heads=1)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): GATv2Conv(64, 1, heads=1)\n",
      ")\n",
      "Start Train\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "\n",
    "in_features = 133                # Количество входных признаков для каждого узла\n",
    "out_features =  1                # Количество выходных признаков\n",
    "num_epochs = 100                 # Количество эпох обучения\n",
    "learning_rate = 0.005            # Скорость обучения\n",
    "weight_decay = 5e-4              # Вес распада для регуляризации\n",
    "warmup_epochs = 2                \n",
    "initial_lr = learning_rate  \n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "hidden_features = 64             # Количество скрытых признаков\n",
    "num_heads = 1                    # Количество \"голов\" в механизме внимания\n",
    "dropout_rate = 0.1                 # Процент дропаута\n",
    "\n",
    "# Определение модели\n",
    "class GATv2Model(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_heads, dropout_rate):\n",
    "        super(GATv2Model, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels=in_features, out_channels=hidden_features,\n",
    "                               heads=num_heads, dropout=dropout_rate, concat=True)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_features * num_heads)\n",
    "        self.conv2 = GATv2Conv(in_channels=hidden_features * num_heads, out_channels=out_features, \n",
    "                               heads=1, concat=False, dropout=dropout_rate)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = F.dropout(x, training=self.training, p=dropout_rate)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x.squeeze()\n",
    "\n",
    "model = GATv2Model(\n",
    "        in_features=in_features,\n",
    "        hidden_features=hidden_features,\n",
    "        out_features=out_features,\n",
    "        num_heads=num_heads,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "print('Start Train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-06 16:57:26,333] A new study created in memory with name: no-name-5ea2b090-9337-4ba2-a71c-25e8fd2a792d\n",
      "[W 2024-03-06 16:57:27,133] Trial 0 failed with parameters: {'hidden_features': 736, 'num_heads': 6, 'dropout_rate': 0.36671834210550686, 'learning_rate': 0.0002770406712453148, 'weight_decay': 4.91967409324119e-05} because of the following error: RuntimeError('CUDA error: no kernel image is available for execution on the device\\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nikolenko/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_4147352/145155110.py\", line 67, in objective\n",
      "    best_val_loss = train_model(trial)\n",
      "  File \"/tmp/ipykernel_4147352/145155110.py\", line 38, in train_model\n",
      "    out = model(batch.x, batch.edge_index)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_4147352/2301756868.py\", line 31, in forward\n",
      "    x = self.conv1(x, edge_index)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py\", line 236, in forward\n",
      "    out = self.propagate(edge_index, x=(x_l, x_r), edge_attr=edge_attr,\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py\", line 374, in propagate\n",
      "    out = self.message(**msg_kwargs)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py\", line 274, in message\n",
      "    alpha = softmax(alpha, index, ptr, size_i)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/utils/softmax.py\", line 43, in softmax\n",
      "    src_max = scatter(src, index, dim, dim_size=N, reduce='max')\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_scatter/scatter.py\", line 160, in scatter\n",
      "    return scatter_max(src, index, dim, out, dim_size)[0]\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_scatter/scatter.py\", line 72, in scatter_max\n",
      "    return torch.ops.torch_scatter.scatter_max(src, index, dim, out, dim_size)\n",
      "  File \"/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/_ops.py\", line 143, in __call__\n",
      "    return self._op(*args, **kwargs or {})\n",
      "RuntimeError: CUDA error: no kernel image is available for execution on the device\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "[W 2024-03-06 16:57:27,135] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/nikolenko/work/gat/hyperopt.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_val_loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m trial \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/nikolenko/work/gat/hyperopt.ipynb Cell 6\u001b[0m line \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(trial):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=66'>67</a>\u001b[0m     best_val_loss \u001b[39m=\u001b[39m train_model(trial)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=67'>68</a>\u001b[0m     save_trial_to_csv(trial\u001b[39m.\u001b[39mnumber, best_val_loss, trial\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=68'>69</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_val_loss\n",
      "\u001b[1;32m/home/nikolenko/work/gat/hyperopt.ipynb Cell 6\u001b[0m line \u001b[0;36mtrain_model\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m out \u001b[39m=\u001b[39m model(batch\u001b[39m.\u001b[39;49mx, batch\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(out, batch\u001b[39m.\u001b[39my)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/nikolenko/work/gat/hyperopt.ipynb Cell 6\u001b[0m line \u001b[0;36mGATv2Model.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bserv2/home/nikolenko/work/gat/hyperopt.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, p\u001b[39m=\u001b[39mdropout_rate)\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:236\u001b[0m, in \u001b[0;36mGATv2Conv.forward\u001b[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe usage of \u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_attr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39madd_self_loops\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39msimultaneously is currently not yet supported for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39medge_index\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in a \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSparseTensor\u001b[39m\u001b[39m'\u001b[39m\u001b[39m form\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m \u001b[39m# propagate_type: (x: PairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49m(x_l, x_r), edge_attr\u001b[39m=\u001b[39;49medge_attr,\n\u001b[1;32m    237\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    239\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha\n\u001b[1;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:374\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 374\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    375\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    376\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/nn/conv/gatv2_conv.py:274\u001b[0m, in \u001b[0;36mGATv2Conv.message\u001b[0;34m(self, x_j, x_i, edge_attr, index, ptr, size_i)\u001b[0m\n\u001b[1;32m    272\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mleaky_relu(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnegative_slope)\n\u001b[1;32m    273\u001b[0m alpha \u001b[39m=\u001b[39m (x \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39matt)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 274\u001b[0m alpha \u001b[39m=\u001b[39m softmax(alpha, index, ptr, size_i)\n\u001b[1;32m    275\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_alpha \u001b[39m=\u001b[39m alpha\n\u001b[1;32m    276\u001b[0m alpha \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(alpha, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_geometric/utils/softmax.py:43\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(src, index, ptr, num_nodes, dim)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39melif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     N \u001b[39m=\u001b[39m maybe_num_nodes(index, num_nodes)\n\u001b[0;32m---> 43\u001b[0m     src_max \u001b[39m=\u001b[39m scatter(src, index, dim, dim_size\u001b[39m=\u001b[39;49mN, reduce\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     44\u001b[0m     src_max \u001b[39m=\u001b[39m src_max\u001b[39m.\u001b[39mindex_select(dim, index)\n\u001b[1;32m     45\u001b[0m     out \u001b[39m=\u001b[39m (src \u001b[39m-\u001b[39m src_max)\u001b[39m.\u001b[39mexp()\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_scatter/scatter.py:160\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, out, dim_size, reduce)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_min(src, index, dim, out, dim_size)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    159\u001b[0m \u001b[39melif\u001b[39;00m reduce \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m scatter_max(src, index, dim, out, dim_size)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch_scatter/scatter.py:72\u001b[0m, in \u001b[0;36mscatter_max\u001b[0;34m(src, index, dim, out, dim_size)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter_max\u001b[39m(\n\u001b[1;32m     69\u001b[0m         src: torch\u001b[39m.\u001b[39mTensor, index: torch\u001b[39m.\u001b[39mTensor, dim: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     70\u001b[0m         out: Optional[torch\u001b[39m.\u001b[39mTensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     71\u001b[0m         dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mtorch_scatter\u001b[39m.\u001b[39;49mscatter_max(src, index, dim, out, dim_size)\n",
      "File \u001b[0;32m/opt/anaconda/envs/torch_gcnn/lib/python3.10/site-packages/torch/_ops.py:143\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    139\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "def save_trial_to_csv(trial_number, trial_value, trial_params, csv_path='optuna_results.csv'):\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if csvfile.tell() == 0:\n",
    "            headers = ['Trial', 'Value'] + [key for key in trial_params.keys()]\n",
    "            writer.writerow(headers)\n",
    "        row = [trial_number, trial_value] + list(trial_params.values())\n",
    "        writer.writerow(row)\n",
    "\n",
    "def train_model(trial):\n",
    "    # Гиперпараметры, подлежащие оптимизации\n",
    "    hidden_features = trial.suggest_int('hidden_features', 32, 1024, step=32)\n",
    "    num_heads = trial.suggest_int('num_heads', 1, 9)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    # еще есть торч лайтнинг\n",
    "\n",
    "    # Создание и обучение модели\n",
    "    model = GATv2Model(in_features, hidden_features, out_features, num_heads, dropout_rate).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch < warmup_epochs:\n",
    "            lr = learning_rate * (epoch + 1) / warmup_epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        else:\n",
    "            lr = learning_rate\n",
    "\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "            batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "            loss = loss_func(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss_accum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc='Validating', leave=False):\n",
    "                batch.to(device)\n",
    "                val_out = model(batch.x, batch.edge_index)\n",
    "                val_loss = loss_func(val_out, batch.y)\n",
    "                val_loss_accum += val_loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss_accum / len(val_loader)\n",
    "        \n",
    "        # Ранняя остановка\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                break\n",
    "\n",
    "    return best_val_loss\n",
    "\n",
    "def objective(trial):\n",
    "    best_val_loss = train_model(trial)\n",
    "    save_trial_to_csv(trial.number, best_val_loss, trial.params)\n",
    "    return best_val_loss\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f' Value: {trial.value}')\n",
    "print(' Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
