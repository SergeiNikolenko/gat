{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda True\n",
      "NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.pruners import SuccessiveHalvingPruner\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "from lion_pytorch import Lion\n",
    "\n",
    "print(\"cuda\", torch.cuda.is_available())  \n",
    "print(torch.cuda.get_device_name(0)) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pytorch_lightning.trainer.connectors.data_connector\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightning_fabric.plugins.environments.slurm\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from utils.train import MoleculeModel, MoleculeDataModule, GATv2Model, get_metric, save_trial_to_csv, create_hyperopt_dir\n",
    "from utils.prepare import FeaturizationParameters, MoleculeDataset, MoleculeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_dataset = torch.load(\"../data/QM_10k.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "in_features = molecule_dataset[0].x.shape[1]\n",
    "edge_attr_dim = molecule_dataset[0].edge_attr.shape[1]\n",
    "max_epochs = 100\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-22 10:18:36,638] A new study created in memory with name: no-name-b25d6a72-1b61-4eb0-92b5-db41d9269162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: hyperopt_2\n",
      "MoleculeModel(\n",
      "  (base_model): GATv2Model(\n",
      "    (atom_preprocess_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=133, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (edge_preprocess_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=14, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (gat_conv_layers): ModuleList(\n",
      "      (0): GATv2Conv(128, 64, heads=8)\n",
      "      (1): GATv2Conv(512, 64, heads=8)\n",
      "    )\n",
      "    (postprocess_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (final_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/sergei/Documents/gat/lightning_logs\n",
      "2024-03-22 10:18:37.147951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[I 2024-03-22 10:20:23,709] Trial 0 finished with value: 0.042822908610105515 and parameters: {'num_preprocess_layers': 2, 'preprocess_layer_0_size': 64, 'preprocess_layer_1_size': 64, 'num_postprocess_layers': 2, 'postprocess_layer_0_size': 64, 'postprocess_layer_1_size': 64, 'num_heads_0': 8, 'num_heads_1': 8, 'dropout_rate_0': 0.0, 'dropout_rate_1': 0.0, 'dropout_rate_2': 0.0, 'dropout_rate_3': 0.0, 'dropout_rate_4': 0.0, 'dropout_rate_5': 0.0, 'use_batch_norm_0': True, 'use_batch_norm_1': True, 'use_batch_norm_2': True, 'use_batch_norm_3': True, 'use_batch_norm_4': True, 'use_batch_norm_5': True}. Best is trial 0 with value: 0.042822908610105515.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 0\n",
      "Best value (RMSE): 0.042822908610105515\n",
      "num_preprocess_layers: 2\n",
      "preprocess_layer_0_size: 64\n",
      "preprocess_layer_1_size: 64\n",
      "num_postprocess_layers: 2\n",
      "postprocess_layer_0_size: 64\n",
      "postprocess_layer_1_size: 64\n",
      "num_heads_0: 8\n",
      "num_heads_1: 8\n",
      "dropout_rate_0: 0.0\n",
      "dropout_rate_1: 0.0\n",
      "dropout_rate_2: 0.0\n",
      "dropout_rate_3: 0.0\n",
      "dropout_rate_4: 0.0\n",
      "dropout_rate_5: 0.0\n",
      "use_batch_norm_0: True\n",
      "use_batch_norm_1: True\n",
      "use_batch_norm_2: True\n",
      "use_batch_norm_3: True\n",
      "use_batch_norm_4: True\n",
      "use_batch_norm_5: True\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Гиперпараметры для предобработки\n",
    "    num_preprocess_layers = trial.suggest_int('num_preprocess_layers', 2, 9)\n",
    "    preprocess_hidden_features = [trial.suggest_categorical(f'preprocess_layer_{i}_size', [64, 128, 256]) for i in range(num_preprocess_layers)]\n",
    "    \n",
    "    # Гиперпараметры для постобработки\n",
    "    num_postprocess_layers = trial.suggest_int('num_postprocess_layers', 2, 9)\n",
    "    postprocess_hidden_features = [trial.suggest_categorical(f'postprocess_layer_{i}_size', [64, 128, 256]) for i in range(num_postprocess_layers)]\n",
    "    \n",
    "    # Другие гиперпараметры\n",
    "    num_heads = [trial.suggest_int(f'num_heads_{i}', 8, 20, step=2) for i in range(2)]\n",
    "    dropout_rates = [trial.suggest_float(f'dropout_rate_{i}', 0.0, 0.2, step=0.1) for i in range(num_preprocess_layers + 2 + num_postprocess_layers)]\n",
    "    use_batch_norm = [trial.suggest_categorical(f'use_batch_norm_{i}', [True, False]) for i in range(num_preprocess_layers + 2 + num_postprocess_layers)]\n",
    "    learning_rate = 8.5e-4\n",
    "    weight_decay = 2e-4\n",
    "    step_size = 50\n",
    "    gamma = 0.1\n",
    "    batch_size = 64\n",
    "\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-6, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
    "    step_size = trial.suggest_int('step_size', 10, 200, step=10)\n",
    "    gamma = trial.suggest_float('gamma', 0.1, 0.9)\n",
    "    #batch_size = trial.suggest_int('batch_size', 64, 128, step=64)\n",
    "\n",
    "    # Создание модели с переменными гиперпараметрами\n",
    "    base_model = GATv2Model(\n",
    "        atom_in_features=in_features,\n",
    "        edge_in_features=edge_attr_dim,\n",
    "        num_preprocess_layers=num_preprocess_layers,\n",
    "        preprocess_hidden_features=preprocess_hidden_features,\n",
    "        num_heads=num_heads,\n",
    "        dropout_rates=dropout_rates,\n",
    "        activation_fns=[nn.ReLU for _ in range(len(dropout_rates))],  # ReLU для всех слоев\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        num_postprocess_layers=num_postprocess_layers,\n",
    "        postprocess_hidden_features=postprocess_hidden_features,\n",
    "        out_features=1\n",
    "    )\n",
    "\n",
    "    model = MoleculeModel(\n",
    "        base_model=base_model,\n",
    "        optimizer_class=Lion,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        step_size=step_size,\n",
    "        gamma=gamma,\n",
    "        batch_size=batch_size,\n",
    "        metric='rmse'\n",
    "    )\n",
    "\n",
    "    # Обучение модели\n",
    "    data_module = MoleculeDataModule(molecule_dataset, batch_size=128, num_workers=num_workers)\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        devices=1,\n",
    "        accelerator='gpu',\n",
    "        logger=False,\n",
    "        enable_progress_bar=False,\n",
    "        enable_checkpointing=False,\n",
    "        enable_model_summary=False,\n",
    "        callbacks=[early_stop_callback]\n",
    "    )\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "\n",
    "    save_trial_to_csv(trial, hyperopt_dir, val_loss)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "hyperopt_dir = create_hyperopt_dir()\n",
    "print(f\"Results will be saved in: {hyperopt_dir}\")\n",
    "\n",
    "pruner = SuccessiveHalvingPruner()\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "study.optimize(objective, n_trials=10000)\n",
    "\n",
    "print(f'Best trial: {study.best_trial.number}')\n",
    "print(f'Best value (RMSE): {study.best_trial.value}')\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geom_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
