{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import csv\n",
    "from rdkit import Chem\n",
    "\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.get_device_name(0)) \n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pytorch_lightning.trainer.connectors.data_connector\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightning_fabric.plugins.environments.slurm\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturizationParameters:\n",
    "    def __init__(self):\n",
    "        self.max_atomic_num = 100\n",
    "        self.atom_features = {\n",
    "            'atomic_num': list(range(self.max_atomic_num)),\n",
    "            'degree': [0, 1, 2, 3, 4, 5],\n",
    "            'formal_charge': [-1, -2, 1, 2, 0],\n",
    "            'chiral_tag': [0, 1, 2, 3],\n",
    "            'num_Hs': [0, 1, 2, 3, 4],\n",
    "            'hybridization': [\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "                Chem.rdchem.HybridizationType.SP3D,\n",
    "                Chem.rdchem.HybridizationType.SP3D2\n",
    "            ],\n",
    "        }\n",
    "        self.atom_fdim = sum(len(choices) + 1 for choices in self.atom_features.values()) + 2\n",
    "\n",
    "def onek_encoding_unk(value, choices):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "def atom_features(atom, params):\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, params.atom_features['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), params.atom_features['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), params.atom_features['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), params.atom_features['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), params.atom_features['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), params.atom_features['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "    return features\n",
    "\n",
    "PARAMS = {\n",
    "    'BOND_FDIM': 10\n",
    "}\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond) -> List[Union[bool, int, float]]:\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (PARAMS['BOND_FDIM'] - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            bond.GetIsConjugated() if bt is not None else 0,\n",
    "            bond.IsInRing() if bt is not None else 0\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond\n",
    "\n",
    "\n",
    "class MoleculeData:\n",
    "    def __init__(self, smiles, target, addHs=True):\n",
    "        self.smiles = smiles\n",
    "        self.target = torch.tensor(target, dtype=torch.float)\n",
    "        self.mol = Chem.MolFromSmiles(smiles)\n",
    "        if addHs:\n",
    "            self.mol = Chem.AddHs(self.mol)\n",
    "        self.params = FeaturizationParameters()\n",
    "        self.edge_index, self.edge_attr = self.construct_graph()\n",
    "\n",
    "    def construct_graph(self):\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for bond in self.mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[start, end], [end, start]])\n",
    "            edge_attr.extend([bond_features(bond), bond_features(bond)])  # Добавляем признаки для обеих направлений связи\n",
    "        return torch.tensor(edge_index).t().contiguous(), torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    def generate_atom_features(self):\n",
    "        features = []\n",
    "        for atom in self.mol.GetAtoms():\n",
    "            features.append(atom_features(atom, self.params))\n",
    "        return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataframe, smiles_column='smiles', target_column='target', addHs=True, n_jobs=-1):\n",
    "        super(MoleculeDataset, self).__init__()\n",
    "        self.data_list = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(lambda row: MoleculeData(row[smiles_column], row[target_column], addHs))(\n",
    "                row) for _, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0]))\n",
    "\n",
    "    def len(self): \n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        molecule_data = self.data_list[idx]\n",
    "        x = molecule_data.generate_atom_features()\n",
    "        edge_index = molecule_data.edge_index\n",
    "        edge_attr = molecule_data.edge_attr\n",
    "        y = molecule_data.target\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        data.smiles = molecule_data.smiles\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_dataset = torch.load('../data/QM_137k.pt')\n",
    "print(molecule_dataset)\n",
    "for i in range(2):\n",
    "    print(molecule_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset, batch_size=128, val_split=0.1, test_split=0.2, num_workers=1):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.val_split = val_split\n",
    "        self.test_split = test_split\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        train_val_indices, test_indices = train_test_split(indices, test_size=self.test_split, random_state=42)\n",
    "        train_indices, val_indices = train_test_split(train_val_indices, test_size=self.val_split / (1 - self.test_split), random_state=42)\n",
    "        \n",
    "        self.train_dataset = Subset(self.dataset, train_indices)\n",
    "        self.val_dataset = Subset(self.dataset, val_indices)\n",
    "        self.test_dataset = Subset(self.dataset, test_indices)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculeModel(pl.LightningModule):\n",
    "    def __init__(self, base_model, optimizer_class, learning_rate, weight_decay, step_size, gamma, batch_size):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.base_model = base_model\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.base_model(x, edge_index)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.hparams.optimizer_class(self.parameters(), lr=self.hparams.learning_rate, weight_decay=self.hparams.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=self.hparams.step_size, gamma=self.hparams.gamma)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch.x, batch.edge_index)\n",
    "        loss = F.mse_loss(y_hat, batch.y)\n",
    "        self.log('train_loss', loss, batch_size=self.batch_size)\n",
    "        self.train_losses.append(loss.item())\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch.x, batch.edge_index)\n",
    "        val_loss = F.mse_loss(y_hat, batch.y)\n",
    "        self.log('val_loss', val_loss, batch_size=self.batch_size)\n",
    "        self.val_losses.append(val_loss.item())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        y_hat = self(batch.x, batch.edge_index)\n",
    "        preds_np = y_hat.detach().cpu().numpy()\n",
    "        true_values_np = batch.y.detach().cpu().numpy()\n",
    "\n",
    "        data = []\n",
    "        start_idx = 0\n",
    "        for i, num_atoms in enumerate(batch.ptr[:-1]): \n",
    "            end_idx = batch.ptr[i+1].item()\n",
    "            molecule_preds = preds_np[start_idx:end_idx]\n",
    "            molecule_true_values = true_values_np[start_idx:end_idx]\n",
    "\n",
    "            data.append({\n",
    "                'smiles': batch.smiles[i],\n",
    "                'predictions': molecule_preds,\n",
    "                'true_values': molecule_true_values\n",
    "            })\n",
    "\n",
    "            start_idx = end_idx\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "    def r2_score(self, y_true, y_pred):\n",
    "        ss_res = torch.sum((y_true - y_pred) ** 2)\n",
    "        ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
    "        r2 = 1 - ss_res / ss_tot\n",
    "        return r2\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        all_data = [item for batch_data in outputs for item in batch_data]\n",
    "        self.df_results = pd.DataFrame(all_data)\n",
    "\n",
    "        all_predictions = np.concatenate(self.df_results['predictions'].values)\n",
    "        all_true_values = np.concatenate(self.df_results['true_values'].values)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(all_true_values, all_predictions))\n",
    "        mse = mean_squared_error(all_true_values, all_predictions)\n",
    "        r2 = r2_score(all_true_values, all_predictions)\n",
    "        mae = mean_absolute_error(all_true_values, all_predictions)\n",
    "\n",
    "        print(f'RMSE: {rmse:.4f}')\n",
    "        print(f'MSE: {mse:.4f}')\n",
    "        print(f'R²: {r2:.4f}')\n",
    "        print(f'MAE: {mae:.4f}')\n",
    "\n",
    "        return self.df_results\n",
    "\n",
    "\n",
    "class GATv2Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_heads, dropout_rate, activation_fn):\n",
    "        super(GATv2Model, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels=in_features, out_channels=hidden_features, heads=num_heads, dropout=dropout_rate, concat=True)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_features * num_heads)\n",
    "        self.conv2 = GATv2Conv(in_channels=hidden_features * num_heads, out_channels=out_features, heads=1, concat=False)\n",
    "        self.activation_fn = activation_fn\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.activation_fn(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "        x = self.conv2(x, edge_index).squeeze()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperopt_dir(base_dir='hyperopt_'):\n",
    "    idx = 1\n",
    "    while True:\n",
    "        dir_name = f\"{base_dir}{idx}\"\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "            return dir_name\n",
    "        idx += 1\n",
    "\n",
    "\n",
    "def save_trial_to_csv(trial, hyperopt_dir, trial_value):\n",
    "    csv_path = os.path.join(hyperopt_dir, 'optuna_results.csv')\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        if os.path.getsize(csv_path) == 0:  \n",
    "            headers = ['Trial'] + [key for key in trial.params.keys()] + ['Value']\n",
    "            writer.writerow(headers)\n",
    "        row = [trial.number] + list(trial.params.values()) + [trial_value]\n",
    "        writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "in_features = molecule_dataset[0].x.shape[1]\n",
    "max_epochs = 1000\n",
    "patience = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_features = trial.suggest_int('hidden_features', 32, 1024, log=True)\n",
    "    num_heads = trial.suggest_int('num_heads', 1, 9)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.6)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
    "    step_size = trial.suggest_int('step_size', 10, 100)\n",
    "    gamma = trial.suggest_float('gamma', 0.1, 0.9)\n",
    "    batch_size = trial.suggest_int('batch_size', 32, 1024, step=32)\n",
    "    activation_name = trial.suggest_categorical('activation_fn', ['relu', 'leaky_relu', 'elu'])\n",
    "    activation_fn = getattr(F, activation_name)\n",
    "\n",
    "\n",
    "    data_module = MoleculeDataModule(molecule_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    base_model = GATv2Model(\n",
    "        in_features=in_features,\n",
    "        hidden_features=hidden_features,\n",
    "        out_features=1,\n",
    "        num_heads=num_heads,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation_fn=activation_fn  \n",
    "    )\n",
    "\n",
    "\n",
    "    model = MoleculeModel(\n",
    "        base_model=base_model,\n",
    "        optimizer_class=torch.optim.Adam,  \n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        step_size=step_size,\n",
    "        gamma=gamma,\n",
    "        batch_size=batch_size  \n",
    "    )\n",
    "\n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss', patience=patience, verbose=False, mode='min')\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,  \n",
    "        accelerator='auto',\n",
    "        callbacks=[early_stop_callback],\n",
    "        logger=False,  \n",
    "        enable_checkpointing=False,\n",
    "        enable_progress_bar=False,  \n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    trial_value = trainer.callback_metrics[\"val_loss\"].item()\n",
    "    save_trial_to_csv(trial, hyperopt_dir, trial_value)\n",
    "\n",
    "    return trial_value\n",
    "\n",
    "hyperopt_dir = create_hyperopt_dir()\n",
    "print(f\"Results will be saved in: {hyperopt_dir}\")\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print(f'Best trial: {study.best_trial.number}')\n",
    "print(f'Best value (validation loss): {study.best_trial.value}')\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f'{key}: {value}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geom_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
