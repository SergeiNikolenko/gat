{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.get_device_name(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturizationParameters:\n",
    "    def __init__(self):\n",
    "        self.max_atomic_num = 100\n",
    "        self.atom_features = {\n",
    "            'atomic_num': list(range(self.max_atomic_num)),\n",
    "            'degree': [0, 1, 2, 3, 4, 5],\n",
    "            'formal_charge': [-1, -2, 1, 2, 0],\n",
    "            'chiral_tag': [0, 1, 2, 3],\n",
    "            'num_Hs': [0, 1, 2, 3, 4],\n",
    "            'hybridization': [\n",
    "                Chem.rdchem.HybridizationType.SP,\n",
    "                Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3,\n",
    "                Chem.rdchem.HybridizationType.SP3D,\n",
    "                Chem.rdchem.HybridizationType.SP3D2\n",
    "            ],\n",
    "        }\n",
    "        self.atom_fdim = sum(len(choices) + 1 for choices in self.atom_features.values()) + 2\n",
    "        # skipatom\n",
    "        # посмотреть какие атомные фичи есть\n",
    "\n",
    "def onek_encoding_unk(value, choices):\n",
    "    encoding = [0] * (len(choices) + 1)\n",
    "    index = choices.index(value) if value in choices else -1\n",
    "    encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "def atom_features(atom, params):\n",
    "    features = onek_encoding_unk(atom.GetAtomicNum() - 1, params.atom_features['atomic_num']) + \\\n",
    "               onek_encoding_unk(atom.GetTotalDegree(), params.atom_features['degree']) + \\\n",
    "               onek_encoding_unk(atom.GetFormalCharge(), params.atom_features['formal_charge']) + \\\n",
    "               onek_encoding_unk(int(atom.GetChiralTag()), params.atom_features['chiral_tag']) + \\\n",
    "               onek_encoding_unk(int(atom.GetTotalNumHs()), params.atom_features['num_Hs']) + \\\n",
    "               onek_encoding_unk(int(atom.GetHybridization()), params.atom_features['hybridization']) + \\\n",
    "               [1 if atom.GetIsAromatic() else 0] + \\\n",
    "               [atom.GetMass() * 0.01]  # scaled to about the same range as other features\n",
    "    return features\n",
    "\n",
    "PARAMS = {\n",
    "    'BOND_FDIM': 10\n",
    "}\n",
    "\n",
    "def bond_features(bond: Chem.rdchem.Bond) -> List[Union[bool, int, float]]:\n",
    "    if bond is None:\n",
    "        fbond = [1] + [0] * (PARAMS['BOND_FDIM'] - 1)\n",
    "    else:\n",
    "        bt = bond.GetBondType()\n",
    "        fbond = [\n",
    "            0,  # bond is not None\n",
    "            bt == Chem.rdchem.BondType.SINGLE,\n",
    "            bt == Chem.rdchem.BondType.DOUBLE,\n",
    "            bt == Chem.rdchem.BondType.TRIPLE,\n",
    "            bt == Chem.rdchem.BondType.AROMATIC,\n",
    "            bond.GetIsConjugated() if bt is not None else 0,\n",
    "            bond.IsInRing() if bt is not None else 0\n",
    "        ]\n",
    "        fbond += onek_encoding_unk(int(bond.GetStereo()), list(range(6)))\n",
    "    return fbond\n",
    "\n",
    "\n",
    "class MoleculeData:\n",
    "    def __init__(self, smiles, target, addHs=True):\n",
    "        self.smiles = smiles\n",
    "        self.target = torch.tensor(target, dtype=torch.float)\n",
    "        self.mol = Chem.MolFromSmiles(smiles)\n",
    "        if addHs:\n",
    "            self.mol = Chem.AddHs(self.mol)\n",
    "        self.params = FeaturizationParameters()\n",
    "        self.edge_index, self.edge_attr = self.construct_graph()\n",
    "\n",
    "    def construct_graph(self):\n",
    "        edge_index = []\n",
    "        edge_attr = []\n",
    "        for bond in self.mol.GetBonds():\n",
    "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_index.extend([[start, end], [end, start]])\n",
    "            edge_attr.extend([bond_features(bond), bond_features(bond)])  # Добавляем признаки для обеих направлений связи\n",
    "        return torch.tensor(edge_index).t().contiguous(), torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    def generate_atom_features(self):\n",
    "        features = []\n",
    "        for atom in self.mol.GetAtoms():\n",
    "            features.append(atom_features(atom, self.params))\n",
    "        return torch.tensor(features, dtype=torch.float)\n",
    "\n",
    "class MoleculeDataset(Dataset):\n",
    "    def __init__(self, dataframe, smiles_column='smiles', target_column='target', addHs=True, n_jobs=-1):\n",
    "        super(MoleculeDataset, self).__init__()\n",
    "        self.data_list = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(lambda row: MoleculeData(row[smiles_column], row[target_column], addHs))(\n",
    "                row) for _, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0]))\n",
    "\n",
    "    def len(self): \n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        molecule_data = self.data_list[idx]\n",
    "        x = molecule_data.generate_atom_features()\n",
    "        edge_index = molecule_data.edge_index\n",
    "        edge_attr = molecule_data.edge_attr\n",
    "        y = molecule_data.target\n",
    "        \n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        data.smiles = molecule_data.smiles\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_dataset = torch.load('../data/QM_137k.pt')\n",
    "print(molecule_dataset)\n",
    "for i in range(2):\n",
    "    print(molecule_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(molecule_dataset)))\n",
    "train_val_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.125, random_state=42)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "train_dataset = [molecule_dataset[i] for i in tqdm(train_indices, desc=\"Creating Train Dataset\")]\n",
    "val_dataset = [molecule_dataset[i] for i in tqdm(val_indices, desc=\"Creating Validation Dataset\")]\n",
    "test_dataset = [molecule_dataset[i] for i in tqdm(test_indices, desc=\"Creating Test Dataset\")]\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataset = DataLoader(molecule_dataset, batch_size=batch_size)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "\n",
    "in_features = 133                # Количество входных признаков для каждого узла\n",
    "out_features =  1                # Количество выходных признаков\n",
    "num_epochs = 1000                # Количество эпох обучения \n",
    "learning_rate = 0.005            # Скорость обучения\n",
    "weight_decay = 5e-4              # Вес распада для регуляризации\n",
    "warmup_epochs = 2                \n",
    "initial_lr = learning_rate  \n",
    "patience = 100                   \n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "hidden_features = 64             # Количество скрытых признаков\n",
    "num_heads = 1                    # Количество \"голов\" в механизме внимания\n",
    "dropout_rate = 0.1               # Процент дропаута\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Определение модели\n",
    "class GATv2Model(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, num_heads, dropout_rate):\n",
    "        super(GATv2Model, self).__init__()\n",
    "        #MPN простой\n",
    "        self.conv1 = GATv2Conv(in_channels=in_features, out_channels=hidden_features,\n",
    "                               heads=num_heads, dropout=dropout_rate, concat=True)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_features * num_heads)\n",
    "        self.conv2 = GATv2Conv(in_channels=hidden_features * num_heads, out_channels=out_features, \n",
    "                               heads=1, concat=False, dropout=dropout_rate)\n",
    "        #FFN слой \n",
    "        # убрать дропаут с выходного\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(self.bn1(x)) # разные hyper\n",
    "        x = F.dropout(x, training=self.training, p=dropout_rate)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x.squeeze()\n",
    "\n",
    "model = GATv2Model(\n",
    "        in_features=in_features,\n",
    "        hidden_features=hidden_features,\n",
    "        out_features=out_features,\n",
    "        num_heads=num_heads,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Model:\\n{model}\")\n",
    "\n",
    "# Определение функции потерь и оптимизатора\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay) #hyper lbfgs\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)   reducelronplate oneciklelr цикл\n",
    "\n",
    "\n",
    "\n",
    "print('Start Train')\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Разогревочные эпохи ????\n",
    "    if epoch < warmup_epochs:\n",
    "        lr = initial_lr * (epoch + 1) / warmup_epochs\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    else:\n",
    "        lr = initial_lr\n",
    "    \n",
    "    # Обучение\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = loss_func(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Валидация\n",
    "    model.eval()\n",
    "    val_loss_accum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch.to(device)\n",
    "            val_out = model(batch.x, batch.edge_index)\n",
    "            val_loss = loss_func(val_out, batch.y)\n",
    "            val_loss_accum += val_loss.item()\n",
    "        \n",
    "    avg_val_loss = val_loss_accum / len(val_loader)\n",
    "    val_losses.append(avg_val_loss) \n",
    "    print(f'Epoch {epoch+1} | LR: {lr:.4f} | Train Loss: {loss.item():.4f} | Val Loss: {avg_val_loss:.4f}')\n",
    "    \n",
    "    #scheduler.step()\n",
    "    \n",
    "    # Ранняя остановка\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0\n",
    "        # torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve == patience:\n",
    "            print(f'Early stopping triggered. No improvement in {patience} epochs.')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "all_predictions = []\n",
    "all_true_values = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader: \n",
    "        batch.to(device)\n",
    "        preds = model(batch.x, batch.edge_index)\n",
    "\n",
    "        preds_np = preds.cpu().numpy()\n",
    "        true_values_np = batch.y.cpu().numpy()\n",
    "        all_predictions.extend(preds_np)  \n",
    "        all_true_values.extend(true_values_np)  \n",
    "\n",
    "        start_idx = 0\n",
    "        for i, num_atoms in enumerate(batch.ptr[:-1]): \n",
    "            end_idx = batch.ptr[i+1].item()\n",
    "            molecule_preds = preds_np[start_idx:end_idx]\n",
    "            molecule_true_values = true_values_np[start_idx:end_idx]\n",
    "\n",
    "            data.append({\n",
    "                'smiles': batch.smiles[i],\n",
    "                'predictions': molecule_preds,\n",
    "                'true_values': molecule_true_values\n",
    "            })\n",
    "\n",
    "            start_idx = end_idx  \n",
    "\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "all_predictions = []\n",
    "all_true_values = []\n",
    "\n",
    "for index, row in df_results.iterrows():\n",
    "    all_predictions.extend(row['predictions'])\n",
    "    all_true_values.extend(row['true_values'])\n",
    "\n",
    "all_predictions_array = np.array(all_predictions)\n",
    "all_true_values_array = np.array(all_true_values)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(all_true_values_array, all_predictions_array))\n",
    "mse = mean_squared_error(all_true_values_array, all_predictions_array)\n",
    "r2 = r2_score(all_true_values_array, all_predictions_array)\n",
    "mae = mean_absolute_error(all_true_values_array, all_predictions_array)\n",
    "\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'R²: {r2:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "\n",
    "smiles = df_results.iloc[0]['smiles']\n",
    "predictions = np.round(df_results.iloc[0]['predictions'], 2)\n",
    "\n",
    "\n",
    "mol = Chem.AddHs(Chem.MolFromSmiles(smiles))\n",
    "\n",
    "for atom, pred in zip(mol.GetAtoms(), predictions):\n",
    "    atom.SetProp('atomNote', str(pred))\n",
    "\n",
    "\n",
    "img = Draw.MolToImage(mol, size=(600, 600), kekulize=True)\n",
    "\n",
    "# Показать изображение\n",
    "img.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
